{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install torch transformers accelerate bitsandbytes peft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\quantizers\\auto.py:212: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "# 4 bit quantized inference \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "model_id = \"meta-llama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                  # Load weights in 4-bit precision (very low memory use)\n",
    "    bnb_4bit_use_double_quant=True,     # Additional optimization to further save memory\n",
    "    bnb_4bit_quant_type=\"nf4\",          # NormalFloat4: good precision/memory trade-off\n",
    "    bnb_4bit_compute_dtype=\"float16\",   # Computation done in float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./quantized_model\",\n",
    "    #model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"./quantized_model\",\n",
    "    #model_id,\n",
    ")\n",
    "\n",
    "# Save quantized model and tokenizer to disk\n",
    "#model.save_pretrained(\"./quantized_model\")\n",
    "#tokenizer.save_pretrained(\"./quantized_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 16384,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.50.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32016\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a commit risk analysis assistant.\n",
      "Your job is to analyze a commit diff and determine if it introduces a software bug.\n",
      "\n",
      "Respond only with 0 (clean) or 1 (risky). Do not include explanations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a commit risk analysis assistant.\n",
    "Your job is to analyze a commit diff and determine if it introduces a software bug.\n",
    "\n",
    "Respond only with 0 (clean) or 1 (risky). Do not include explanations.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"  # for instruction models\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "print(SYSTEM_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "pre_prompt = \"\"\" # commit info:\n",
    "\n",
    "Title: Fix API version in pom.xml  Change-Id: Id96d71ccb150c18a15291c01296a8152c6ec3eb0\n",
    "Diff:\n",
    "diff --git a/pom.xml b/pom.xml\n",
    "index d33e954..ddd1e98 100644\n",
    "--- a/pom.xml\n",
    "+++ b/pom.xml\n",
    "@@ -22,7 +22,7 @@ limitations under the License.\n",
    "   <groupId>com.googlesource.gerrit.plugins</groupId>\n",
    "   <artifactId>delete-project</artifactId>\n",
    "   <packaging>jar</packaging>\n",
    "-  <version>2.12-SNAPSHOT</version>\n",
    "+  <version>2.12</version>\n",
    "   <properties>\n",
    "     <Gerrit-ApiType>plugin</Gerrit-ApiType>\n",
    "     <Gerrit-ApiVersion>${project.version}</Gerrit-ApiVersion>\n",
    "# risk value:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"{B_INST} {B_SYS}{SYSTEM_PROMPT}{E_SYS}{pre_prompt} {E_INST}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   518, 25580, 29962,  3532, 14816, 29903,  6778,    13,  3492,\n",
       "           526,   263,  9063, 12045,  7418, 20255, 29889,    13, 10858,  4982,\n",
       "           338,   304, 27599,   263,  9063,  2923,   322,  8161,   565,   372,\n",
       "          4547,   778,   263,  7047,  6494, 29889,    13,    13,  1666,  2818,\n",
       "           871,   411, 29871, 29900,   313, 14941, 29897,   470, 29871, 29896,\n",
       "           313,  3780,  3459,   467,  1938,   451,  3160,  7309,   800, 29889,\n",
       "            13,    13, 29966,   829, 14816, 29903,  6778,    13,    13,   396,\n",
       "          9063,  5235, 29901,    13,    13,  7030, 29901, 24778,  3450,  1873,\n",
       "           297,  8280, 29889,  3134, 29871, 10726, 29899,  1204, 29901,  5163,\n",
       "         29929, 29953, 29881, 29955, 29896,   617, 29890, 29896, 29945, 29900,\n",
       "         29883, 29896, 29947, 29874, 29896, 29945, 29906, 29929, 29896, 29883,\n",
       "         29900, 29896, 29906, 29929, 29953, 29874, 29947, 29896, 29945, 29906,\n",
       "         29883, 29953,   687, 29941,   774, 29900,    13, 26023, 29901,    13,\n",
       "         12765,  1192,  5559,   263, 29914, 29533, 29889,  3134,   289, 29914,\n",
       "         29533, 29889,  3134,    13,  2248,   270, 29941, 29941, 29872, 29929,\n",
       "         29945, 29946,   636,  1289, 29881, 29896, 29872, 29929, 29947, 29871,\n",
       "         29896, 29900, 29900, 29953, 29946, 29946,    13,  5634,   263, 29914,\n",
       "         29533, 29889,  3134,    13,  1817, 29974,   289, 29914, 29533, 29889,\n",
       "          3134,    13, 25380,   448, 29906, 29906, 29892, 29955,   718, 29906,\n",
       "         29906, 29892, 29955,   732, 29992, 27028,  1090,   278, 19245, 29889,\n",
       "            13,   259,   529,  9688, 29958,   510, 29889,  1484,   468,   793,\n",
       "          1167, 29889,   914,   768, 29889, 12800,   829,  9688, 29958,    13,\n",
       "           259,   529,  9680, 29958,  8143, 29899,  4836,   829,  9680, 29958,\n",
       "            13,   259,   529,  4058,  6751, 29958,  4758,   829,  4058,  6751,\n",
       "         29958,    13, 29899, 29871,   529,  3259, 29958, 29906, 29889, 29896,\n",
       "         29906, 29899, 19296,  3301,  7068,  2891,   829,  3259, 29958,    13,\n",
       "         29974, 29871,   529,  3259, 29958, 29906, 29889, 29896, 29906,   829,\n",
       "          3259, 29958,    13,   259,   529, 11330, 29958,    13,   268,   529,\n",
       "         29954,   261,   768, 29899, 11713,  1542, 29958,  8582,   829, 29954,\n",
       "           261,   768, 29899, 11713,  1542, 29958,    13,   268,   529, 29954,\n",
       "           261,   768, 29899, 11713,  6594, 29958,  5303,  4836, 29889,  3259,\n",
       "         16040, 29954,   261,   768, 29899, 11713,  6594, 29958,    13, 29937,\n",
       "         12045,   995, 29901,    13,   518, 29914, 25580, 29962]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "runtimeFlag = \"cuda\"\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise ValueError(\"CUDA GPU is not available. Ensure GPU and CUDA are properly installed.\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=True,\n",
    "    padding=True  # ensures attention mask is properly generated\n",
    ").to(runtimeFlag)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: ?\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1,            # expecting a single token (\"0\" or \"1\")\n",
    "    do_sample=False,             # deterministic output (no randomness)\n",
    "    pad_token_id=tokenizer.eos_token_id  # clearly specify pad token\n",
    ")\n",
    "\n",
    "# Decode and print the result\n",
    "result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "response = result.strip()[-1] if result.strip()[-1] in {\"0\", \"1\"} else \"?\"\n",
    "print(\"Predicted label:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model response: [INST] <<SYS>>\n",
      "You are a commit risk analysis assistant.\n",
      "Your job is to analyze a commit diff and determine if it introduces a software bug.\n",
      "\n",
      "Respond only with 0 (clean) or 1 (risky). Do not include explanations.\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      " # commit info:\n",
      "\n",
      "Title: Fix API version in pom.xml  Change-Id: Id96d71ccb150c18a15291c01296a8152c6ec3eb0\n",
      "Diff:\n",
      "diff --git a/pom.xml b/pom.xml\n",
      "index d33e954..ddd1e98 100644\n",
      "--- a/pom.xml\n",
      "+++ b/pom.xml\n",
      "@@ -22,7 +22,7 @@ limitations under the License.\n",
      "   <groupId>com.googlesource.gerrit.plugins</groupId>\n",
      "   <artifactId>delete-project</artifactId>\n",
      "   <packaging>jar</packaging>\n",
      "-  <version>2.12-SNAPSHOT</version>\n",
      "+  <version>2.12</version>\n",
      "   <properties>\n",
      "     <Gerrit-ApiType>plugin</Gerrit-ApiType>\n",
      "     <Gerrit-ApiVersion>${project.version}</Gerrit-ApiVersion>\n",
      "# risk value:\n",
      " [/INST]\n"
     ]
    }
   ],
   "source": [
    "print(\"Full model response:\", result.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the raw text data from file\n",
    "with open('G:/defect-prediction-project/datasets/finetune_data/train_openllama_go.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract data from your raw text\n",
    "pattern = r'\\[DEFECT\\]\\nTitle:(.*?)\\nDiff:\\n(.*?)\\[/DEFECT\\]\\n(\\d)'\n",
    "matches = re.findall(pattern, raw_text, re.DOTALL)\n",
    "\n",
    "data = []\n",
    "for match in matches:\n",
    "    commit_info = match[0].strip()\n",
    "    diff = match[1].strip()\n",
    "    label = int(match[2].strip())\n",
    "    data.append({'commit_info': f'Title: {commit_info}', 'diff': diff, 'label': label})\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Write directly to JSON files (no JSONL)\n",
    "with open('train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "\n",
    "with open('validation.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(val_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sarra\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarra\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarra\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarra\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in g:\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarra\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['commit_info', 'diff', 'label'],\n",
      "        num_rows: 14703\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['commit_info', 'diff', 'label'],\n",
      "        num_rows: 3676\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('json', data_files={\n",
    "    'train': 'train.json',\n",
    "    'validation': 'validation.json'\n",
    "})\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a commit risk analysis assistant.\n",
    "Your job is to analyze a commit diff and determine if it introduces a software bug.\n",
    "\n",
    "Respond only with 0 (clean) or 1 (risky). Do not include explanations.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "def format_prompt(data_point):\n",
    "    return f\"{B_INST} {B_SYS}{SYSTEM_PROMPT}{E_SYS}# commit info:\\n{data_point['commit_info']}\\n\\nDiff:\\n{data_point['diff']}\\n\\n# risk value:\\n{data_point['label']} {E_INST}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_batch):\n",
    "    prompts = [\n",
    "        format_prompt({\"commit_info\": ci, \"diff\": d, \"label\": l})\n",
    "        for ci, d, l in zip(data_batch[\"commit_info\"], data_batch[\"diff\"], data_batch[\"label\"])\n",
    "    ]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        prompts,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = [ids.copy() for ids in tokenized[\"input_ids\"]]\n",
    "\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555ea99d648342aaa998b37a0991909f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41295218ba9040d08f2818a660e65c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenized_train_dataset = dataset['train'].map(\n",
    "    generate_and_tokenize_prompt,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "tokenized_val_dataset = dataset['validation'].map(\n",
    "    generate_and_tokenize_prompt,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 599, 29901, 2329, 4274, 7911, 1066, 29871, 263, 1599, 385, 29871, 10726, 29899, 1204, 29901, 306, 29929, 29945, 29874, 29929, 29946, 29900, 2176, 29953, 29946, 10702, 29947, 29906, 29945, 29947, 29947, 29955, 29890, 29955, 29945, 29874, 29947, 29900, 1479, 29883, 29947, 29906, 29906, 29900, 29929, 29945, 29890, 29946, 29929, 29955, 29947, 29896, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29953, 29941, 29929, 29929, 29896, 7525, 29899, 15870, 29933, 327, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 2248, 29871, 29906, 29881, 29896, 29946, 29883, 29906, 29874, 636, 10702, 29947, 29888, 12328, 29945, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 1817, 29974, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 25380, 448, 29906, 29892, 29955, 718, 29906, 29892, 29955, 732, 29992, 13, 849, 4803, 310, 445, 2752, 775, 338, 4095, 287, 491, 263, 350, 7230, 29899, 3293, 13, 849, 19405, 393, 508, 367, 1476, 297, 278, 365, 2965, 1430, 1660, 934, 29889, 13, 29871, 13, 29899, 458, 1334, 505, 263, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 29974, 458, 1334, 505, 385, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 849, 1661, 29899, 22490, 29953, 29946, 21796, 29889, 450, 626, 29881, 29953, 29946, 11470, 947, 451, 2304, 20243, 1484, 29889, 13, 849, 718, 4282, 1738, 22490, 29953, 29946, 20243, 1484, 623, 10599, 13, 29871, 13, 12765, 1192, 5559, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 289, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 13, 2248, 274, 29896, 29953, 1389, 29955, 29947, 636, 562, 29953, 29945, 29896, 29881, 29929, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 599, 29901, 2329, 4274, 7911, 1066, 29871, 263, 1599, 385, 29871, 10726, 29899, 1204, 29901, 306, 29929, 29945, 29874, 29929, 29946, 29900, 2176, 29953, 29946, 10702, 29947, 29906, 29945, 29947, 29947, 29955, 29890, 29955, 29945, 29874, 29947, 29900, 1479, 29883, 29947, 29906, 29906, 29900, 29929, 29945, 29890, 29946, 29929, 29955, 29947, 29896, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29953, 29941, 29929, 29929, 29896, 7525, 29899, 15870, 29933, 327, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 2248, 29871, 29906, 29881, 29896, 29946, 29883, 29906, 29874, 636, 10702, 29947, 29888, 12328, 29945, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 1817, 29974, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 25380, 448, 29906, 29892, 29955, 718, 29906, 29892, 29955, 732, 29992, 13, 849, 4803, 310, 445, 2752, 775, 338, 4095, 287, 491, 263, 350, 7230, 29899, 3293, 13, 849, 19405, 393, 508, 367, 1476, 297, 278, 365, 2965, 1430, 1660, 934, 29889, 13, 29871, 13, 29899, 458, 1334, 505, 263, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 29974, 458, 1334, 505, 385, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 849, 1661, 29899, 22490, 29953, 29946, 21796, 29889, 450, 626, 29881, 29953, 29946, 11470, 947, 451, 2304, 20243, 1484, 29889, 13, 849, 718, 4282, 1738, 22490, 29953, 29946, 20243, 1484, 623, 10599, 13, 29871, 13, 12765, 1192, 5559, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 289, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 13, 2248, 274, 29896, 29953, 1389, 29955, 29947, 636, 562, 29953, 29945, 29896, 29881, 29929, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 2]}\n",
      "{'input_ids': [1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 274, 17929, 29914, 29916, 29945, 29900, 29929, 29901, 2767, 10012, 3876, 2284, 29879, 29889, 29871, 12113, 3939, 278, 3402, 310, 967, 2304, 1813, 29892, 577, 591, 817, 304, 1791, 1247, 545, 278, 4544, 13812, 29889, 450, 4544, 1591, 338, 1286, 21213, 773, 4943, 12241, 29892, 322, 23199, 1078, 526, 769, 1476, 297, 5825, 3267, 9311, 3787, 491, 1009, 19917, 2158, 29889, 29871, 24778, 267, 396, 29906, 29906, 29896, 29947, 29896, 29871, 10726, 29899, 1204, 29901, 306, 29906, 29929, 29872, 29955, 29874, 29946, 29900, 29881, 29941, 29955, 29955, 29955, 29900, 1327, 29900, 29900, 29945, 29881, 29955, 29906, 29947, 29888, 29896, 29947, 29941, 29906, 29906, 29929, 29929, 29883, 29945, 29906, 29947, 29953, 29929, 29896, 29888, 29955, 29872, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29955, 29955, 29906, 29945, 29906, 7525, 29899, 15870, 29933, 327, 29901, 15862, 22963, 5031, 9131, 529, 1182, 328, 29888, 2784, 29992, 29887, 324, 574, 29889, 990, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 11783, 10476, 2330, 529, 351, 29880, 29992, 29887, 324, 574, 29889, 990, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 289, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 2248, 285, 29883, 29906, 29946, 29947, 29947, 328, 29883, 29953, 636, 29890, 29945, 29945, 29947, 29900, 29881, 29953, 29888, 29900, 29906, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 1817, 29974, 289, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 25380, 448, 29896, 29947, 29892, 29896, 29953, 718, 29896, 29947, 29892, 29896, 29947, 732, 29992, 3577, 1667, 13, 29871, 13, 1053, 313, 13, 29871, 12, 29908, 13193, 29908, 13, 29974, 12, 29908, 29883, 17929, 29914, 17051, 29906, 29945, 29953, 29908, 13, 29871, 12, 29908, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29908, 13, 29974, 12, 29908, 22331, 29914, 20970, 29908, 13, 29871, 12, 29908, 22331, 29914, 29886, 331, 29908, 13, 29871, 12, 29908, 15581, 29908, 13, 29871, 12, 29908, 23479, 29908, 13, 29871, 12, 29908, 1484, 29914, 4830, 29908, 13, 29871, 12, 29908, 601, 29914, 29875, 449, 309, 29908, 13, 29871, 12, 29908, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 274, 17929, 29914, 29916, 29945, 29900, 29929, 29901, 2767, 10012, 3876, 2284, 29879, 29889, 29871, 12113, 3939, 278, 3402, 310, 967, 2304, 1813, 29892, 577, 591, 817, 304, 1791, 1247, 545, 278, 4544, 13812, 29889, 450, 4544, 1591, 338, 1286, 21213, 773, 4943, 12241, 29892, 322, 23199, 1078, 526, 769, 1476, 297, 5825, 3267, 9311, 3787, 491, 1009, 19917, 2158, 29889, 29871, 24778, 267, 396, 29906, 29906, 29896, 29947, 29896, 29871, 10726, 29899, 1204, 29901, 306, 29906, 29929, 29872, 29955, 29874, 29946, 29900, 29881, 29941, 29955, 29955, 29955, 29900, 1327, 29900, 29900, 29945, 29881, 29955, 29906, 29947, 29888, 29896, 29947, 29941, 29906, 29906, 29929, 29929, 29883, 29945, 29906, 29947, 29953, 29929, 29896, 29888, 29955, 29872, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29955, 29955, 29906, 29945, 29906, 7525, 29899, 15870, 29933, 327, 29901, 15862, 22963, 5031, 9131, 529, 1182, 328, 29888, 2784, 29992, 29887, 324, 574, 29889, 990, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 11783, 10476, 2330, 529, 351, 29880, 29992, 29887, 324, 574, 29889, 990, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 289, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 2248, 285, 29883, 29906, 29946, 29947, 29947, 328, 29883, 29953, 636, 29890, 29945, 29945, 29947, 29900, 29881, 29953, 29888, 29900, 29906, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 1817, 29974, 289, 29914, 4351, 29914, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29914, 4632, 29918, 16702, 5080, 29918, 2817, 29918, 1885, 29889, 1484, 13, 25380, 448, 29896, 29947, 29892, 29896, 29953, 718, 29896, 29947, 29892, 29896, 29947, 732, 29992, 3577, 1667, 13, 29871, 13, 1053, 313, 13, 29871, 12, 29908, 13193, 29908, 13, 29974, 12, 29908, 29883, 17929, 29914, 17051, 29906, 29945, 29953, 29908, 13, 29871, 12, 29908, 29883, 17929, 29914, 29916, 29945, 29900, 29929, 29908, 13, 29974, 12, 29908, 22331, 29914, 20970, 29908, 13, 29871, 12, 29908, 22331, 29914, 29886, 331, 29908, 13, 29871, 12, 29908, 15581, 29908, 13, 29871, 12, 29908, 23479, 29908, 13, 29871, 12, 29908, 1484, 29914, 4830, 29908, 13, 29871, 12, 29908, 601, 29914, 29875, 449, 309, 29908, 13, 29871, 12, 29908, 2]}\n",
      "[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 599, 29901, 2329, 4274, 7911, 1066, 29871, 263, 1599, 385, 29871, 10726, 29899, 1204, 29901, 306, 29929, 29945, 29874, 29929, 29946, 29900, 2176, 29953, 29946, 10702, 29947, 29906, 29945, 29947, 29947, 29955, 29890, 29955, 29945, 29874, 29947, 29900, 1479, 29883, 29947, 29906, 29906, 29900, 29929, 29945, 29890, 29946, 29929, 29955, 29947, 29896, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29953, 29941, 29929, 29929, 29896, 7525, 29899, 15870, 29933, 327, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 2248, 29871, 29906, 29881, 29896, 29946, 29883, 29906, 29874, 636, 10702, 29947, 29888, 12328, 29945, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 1817, 29974, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 25380, 448, 29906, 29892, 29955, 718, 29906, 29892, 29955, 732, 29992, 13, 849, 4803, 310, 445, 2752, 775, 338, 4095, 287, 491, 263, 350, 7230, 29899, 3293, 13, 849, 19405, 393, 508, 367, 1476, 297, 278, 365, 2965, 1430, 1660, 934, 29889, 13, 29871, 13, 29899, 458, 1334, 505, 263, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 29974, 458, 1334, 505, 385, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 849, 1661, 29899, 22490, 29953, 29946, 21796, 29889, 450, 626, 29881, 29953, 29946, 11470, 947, 451, 2304, 20243, 1484, 29889, 13, 849, 718, 4282, 1738, 22490, 29953, 29946, 20243, 1484, 623, 10599, 13, 29871, 13, 12765, 1192, 5559, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 289, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 13, 2248, 274, 29896, 29953, 1389, 29955, 29947, 636, 562, 29953, 29945, 29896, 29881, 29929, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 2]\n",
      "[1, 518, 25580, 29962, 3532, 14816, 29903, 6778, 13, 3492, 526, 263, 9063, 12045, 7418, 20255, 29889, 13, 10858, 4982, 338, 304, 27599, 263, 9063, 2923, 322, 8161, 565, 372, 4547, 778, 263, 7047, 6494, 29889, 13, 13, 1666, 2818, 871, 411, 29871, 29900, 313, 14941, 29897, 470, 29871, 29896, 313, 3780, 3459, 467, 1938, 451, 3160, 7309, 800, 29889, 13, 13, 29966, 829, 14816, 29903, 6778, 13, 13, 29937, 9063, 5235, 29901, 13, 7030, 29901, 599, 29901, 2329, 4274, 7911, 1066, 29871, 263, 1599, 385, 29871, 10726, 29899, 1204, 29901, 306, 29929, 29945, 29874, 29929, 29946, 29900, 2176, 29953, 29946, 10702, 29947, 29906, 29945, 29947, 29947, 29955, 29890, 29955, 29945, 29874, 29947, 29900, 1479, 29883, 29947, 29906, 29906, 29900, 29929, 29945, 29890, 29946, 29929, 29955, 29947, 29896, 13957, 287, 29899, 265, 29901, 2045, 597, 1484, 29899, 27828, 29889, 1484, 468, 793, 1167, 29889, 510, 29914, 29953, 29941, 29929, 29929, 29896, 7525, 29899, 15870, 29933, 327, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 3967, 29933, 327, 29899, 3591, 29901, 402, 711, 327, 402, 711, 327, 529, 29887, 711, 327, 29992, 29887, 324, 574, 29889, 990, 29958, 13957, 287, 29899, 1609, 29901, 4827, 478, 351, 11222, 529, 1289, 359, 29992, 3608, 29889, 510, 29958, 13, 13, 26023, 29901, 13, 12765, 1192, 5559, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 2248, 29871, 29906, 29881, 29896, 29946, 29883, 29906, 29874, 636, 10702, 29947, 29888, 12328, 29945, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 1817, 29974, 289, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29914, 2764, 345, 29906, 29945, 29945, 29896, 29929, 29889, 1484, 13, 25380, 448, 29906, 29892, 29955, 718, 29906, 29892, 29955, 732, 29992, 13, 849, 4803, 310, 445, 2752, 775, 338, 4095, 287, 491, 263, 350, 7230, 29899, 3293, 13, 849, 19405, 393, 508, 367, 1476, 297, 278, 365, 2965, 1430, 1660, 934, 29889, 13, 29871, 13, 29899, 458, 1334, 505, 263, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 29974, 458, 1334, 505, 385, 5314, 297, 626, 29881, 29953, 29946, 11470, 577, 445, 775, 338, 871, 1065, 373, 13, 849, 1661, 29899, 22490, 29953, 29946, 21796, 29889, 450, 626, 29881, 29953, 29946, 11470, 947, 451, 2304, 20243, 1484, 29889, 13, 849, 718, 4282, 1738, 22490, 29953, 29946, 20243, 1484, 623, 10599, 13, 29871, 13, 12765, 1192, 5559, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 289, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 29918, 1989, 29918, 1688, 29889, 1484, 13, 2248, 274, 29896, 29953, 1389, 29955, 29947, 636, 562, 29953, 29945, 29896, 29881, 29929, 29871, 29896, 29900, 29900, 29953, 29946, 29946, 13, 5634, 263, 29914, 3150, 4061, 29886, 29914, 4058, 300, 29914, 9053, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_dataset[0])\n",
    "print(tokenized_val_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup QLoRA\n",
    "output_dir = \"G:/pie-perf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 6,755,323,904 || trainable%: 0.2484\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    # prepare_model_for_int8_training,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "\n",
    "model.train() # put model back into training mode\n",
    "# model = prepare_model_for_int8_training(model)  # get the model ready for int8 quantization\n",
    "model = prepare_model_for_kbit_training(model)  # get the model ready for int8 quantization\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                    # Rank (controls low-rank decomposition size)\n",
    "    lora_alpha=32,           # Scaling factor (commonly alpha=2*r)\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # targeted modules for LoRA\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply QLoRA to your model explicitly\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint G:/pie-perf/checkpoint-220/adapter_model.bin not found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from peft import set_peft_model_state_dict\n",
    "\n",
    "# set this to the adapter_model.bin file you want to resume from (if any)\n",
    "resume_from_checkpoint = \"./qlora_commit_model/checkpoint-220/adapter_model.bin\"\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    if os.path.exists(resume_from_checkpoint):\n",
    "        print(f\"Restarting from {resume_from_checkpoint}\")\n",
    "        adapters_weights = torch.load(resume_from_checkpoint)\n",
    "        set_peft_model_state_dict(model, adapters_weights)\n",
    "    else:\n",
    "        print(f\"Checkpoint {resume_from_checkpoint} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "per_device_train_batch_size = 8\n",
    "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=100,\n",
    "        max_steps=400,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        eval_strategy=\"steps\", # if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_steps=20,\n",
    "        output_dir=\"./qlora_commit_model\",\n",
    "        # save_total_limit=3,\n",
    "        load_best_model_at_end=False,\n",
    "        # ddp_find_unused_parameters=False if ddp else None,\n",
    "        group_by_length=True, # group sequences of roughly the same length together to speed up training\n",
    "        report_to=\"none\",\n",
    "        run_name=None\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21/400 27:57 < 9:17:38, 0.01 it/s, Epoch 0.17/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.749600</td>\n",
       "      <td>1.685997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
